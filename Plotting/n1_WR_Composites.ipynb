{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b946a06-4c28-4bc6-a3c8-039f4112c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.path as mpath\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.feature as cf\n",
    "import shapely.geometry as sgeom\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "import pickle\n",
    "import copy\n",
    "from shapely import geometry\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f4a33c-88e3-4007-a55a-0f1cbeb67f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_reanalyses = ['ERA5',\n",
    "                   'JRA3Q',\n",
    "                   'NCEP_NCAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477bba79-d74a-43fa-ba3f-b67f793a20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_anoms = '/glade/derecho/scratch/jhayron/Data4WRsClimateChange/ProcessedDataReanalyses/'\n",
    "path_pcs = '/glade/derecho/scratch/jhayron/Data4WRsClimateChange/PCs_Z500/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4799e4-bc20-499b-9a31-594a1094abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_labels = {}\n",
    "for reanalysis in names_reanalyses:\n",
    "    labels_temp = pd.read_csv(f'../ProcessZ500/labels/df_labels_{reanalysis}.csv', \n",
    "                              parse_dates=True, index_col=0, names=['WR','distances','corr'], skiprows=1)\n",
    "    dic_labels[reanalysis] = labels_temp[['WR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257dcc75-fd06-4481-835e-17c860a5232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_fields_for_centroids(dataarray,labels):\n",
    "    wrs = np.unique(labels)\n",
    "    avgs = []\n",
    "    for wr in wrs:\n",
    "        df_wr = labels[labels['WR']==wr]\n",
    "        arr_selection = dataarray.sel(time=df_wr.index)\n",
    "        averagefield = arr_selection.mean('time')\n",
    "        avgs.append(averagefield)\n",
    "    return xr.concat(avgs,dim='WR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7900619-9cd2-43e9-9545-c0372ea2a98d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for reanalysis in names_reanalyses:\n",
    "for reanalysis in ['ERA5']:\n",
    "    anoms = xr.open_dataset(f'{path_anoms}Z500Anoms_{reanalysis}.nc')\n",
    "    labels_temp = pd.read_csv(f'../ProcessZ500/labels/df_labels_{reanalysis}.csv', \n",
    "                              parse_dates=True, index_col=0, names=['WR','distances','corr'], skiprows=1)\n",
    "    labels_temp.loc[labels_temp['corr']<=0.25,'WR']=np.unique(labels_temp['WR'])[-1]\n",
    "    composites = get_average_fields_for_centroids(anoms, labels_temp[['WR']])\n",
    "    # composites.to_netcdf(f'composites/composites_{reanalysis}_March23_2025.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ef4272-c5f5-41cb-b590-e2822f6cbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [180, 330, 20, 80]\n",
    "# names = [\"Atlantic High\",\"Greenland High\",\"Pacific Ridge\",\"Pacific Trough\",\"No WR\"]\n",
    "names = [\"Polar High\", \"Pacific Trough (PT)\", \"Pacific Ridge\", \"Alaskan Ridge\", \"Atlantic Ridge\" ,\"No WR\"]\n",
    "# plot_multiple_maps(composites,\n",
    "#                    region,names=names, path_save=f'nFigures/1_Composites_ERA5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a5b429-79a4-4fee-bda5-94d53f86285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_results_best_k = np.load(f'../ProcessZ500/results_best_k/dic_results_best_k_v2.npy',allow_pickle=True)[()]\n",
    "classifiability_synthetic = np.load(f'../ProcessZ500/results_best_k/classifiability_synthetic_v2.npy').tolist()\n",
    "\n",
    "lower_bound_synth_class = np.quantile(classifiability_synthetic,0.9,axis=1)\n",
    "upper_bound_synth_class = np.quantile(classifiability_synthetic,0.10,axis=1)\n",
    "\n",
    "# lower_bound_subsets_class = np.quantile(dic_results_best_k['classifiability_subsets'],0.1,axis=1)\n",
    "# upper_bound_subsets_class = np.quantile(dic_results_best_k['classifiability_subsets'],0.9,axis=1)\n",
    "### Do plot ###\n",
    "lower_bound_synth_class = np.quantile(classifiability_synthetic,0.9,axis=1)\n",
    "upper_bound_synth_class = np.quantile(classifiability_synthetic,0.10,axis=1)\n",
    "\n",
    "q25_synth_class = np.quantile(classifiability_synthetic,0.25,axis=1)\n",
    "q75_synth_class = np.quantile(classifiability_synthetic,0.75,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8910895c-8149-42f2-b84c-cc70c88a236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(10,3))\n",
    "# # axes = axes.flatten()\n",
    "\n",
    "# for k in range(2,11):\n",
    "#     ax.scatter(np.repeat(k,k),\n",
    "#              dic_results_best_k['reproducibility'][k-2],color='k',s=2)\n",
    "#     ax.scatter(k,\n",
    "#              np.mean(dic_results_best_k['reproducibility'][k-2]),\n",
    "#                     color='orange',s=20)\n",
    "# ax.scatter(k,\n",
    "#          np.mean(dic_results_best_k['reproducibility'][k-2]),\n",
    "#                 color='orange',s=20,label='Average clusters')\n",
    "#     # axes[1].axhline(0,color='k')\n",
    "# ax.set_xlabel('Number of clusters (k)')\n",
    "# ax.set_ylabel('Reproducibility')\n",
    "# ax.set_title('Reproducibility Index')\n",
    "# ax.set_xticks(np.arange(2,11))\n",
    "# ax.grid(alpha=0.2,ls='--')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8225049f-a173-4259-907a-f33e0b3250cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d3f25bf-6c4b-4a0c-a1ab-a7cb1fd50a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "da=composites\n",
    "regioncoords=region\n",
    "path_save=f'nFigures/1_WR_Composites_ERA5.png'\n",
    "n_cols=3\n",
    "\n",
    "min_lon, max_lon, min_lat, max_lat = regioncoords\n",
    "# Convert longitudes from 0-360 to -180-180 if necessary\n",
    "def convert_lon(lon):\n",
    "    return lon if lon <= 180 else lon - 360\n",
    "\n",
    "min_lon_converted = convert_lon(min_lon)\n",
    "max_lon_converted = convert_lon(max_lon)\n",
    "\n",
    "# Number of maps to plot\n",
    "n_maps = len(da.WR)\n",
    "\n",
    "# Determine the number of rows needed\n",
    "n_rows = math.ceil(n_maps / n_cols)\n",
    "\n",
    "# Create a figure with the calculated number of subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(9, 2 * (n_rows)),\n",
    "                         subplot_kw={'projection': ccrs.AlbersEqualArea(central_longitude=-115,\n",
    "            central_latitude=50,\n",
    "            standard_parallels=(30, 70))})\n",
    "\n",
    "if n_rows == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "\n",
    "import string\n",
    "abcd = list(string.ascii_lowercase)\n",
    "\n",
    "# Plot each DataArray in the provided list\n",
    "for i in range(len(da.WR.values)-1):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # Convert longitudes to -180 to 180 range\n",
    "    lon = (da.lon + 180) % 360 - 180\n",
    "\n",
    "    # Adjust data array to match the longitude range\n",
    "    da_shifted, lon_shifted = xr.broadcast(da, lon)\n",
    "    ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # Plot the data using pcolormesh\n",
    "    mini=-1\n",
    "    maxi=1\n",
    "    intervals = 21\n",
    "    bounds=np.linspace(mini,maxi,intervals)\n",
    "    mesh = ax.contourf(lon_shifted.sel(WR=i).lon, da.lat, da_shifted.sel(WR=i).Z_anom.values, levels=bounds, vmin=mini, vmax=maxi,\n",
    "                             cmap='bwr', transform=ccrs.PlateCarree(),extend='both')\n",
    "\n",
    "    # Add coastlines for context\n",
    "    ax.coastlines()\n",
    "    ax.margins(x=0, y=0)\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='gray', linewidth=0.5, zorder=5)  # Add country borders\n",
    "    ax.add_feature(cfeature.STATES, edgecolor='gray', linewidth=0.25, zorder=5)  # Add state/province borders\n",
    "\n",
    "    extent = [-180, -30, 20, 80]\n",
    "    # Create a rectangular boundary matching the extent\n",
    "    verts = [\n",
    "        (extent[0], extent[2]),  # Bottom-left corner\n",
    "        (extent[1], extent[2]),  # Bottom-right corner\n",
    "        (extent[1], extent[3]),  # Top-right corner\n",
    "        (extent[0], extent[3]),  # Top-left corner\n",
    "        (extent[0], extent[2])   # Closing the rectangle\n",
    "    ]\n",
    "    rect = mpath.Path(verts)\n",
    "    # Set the boundary of the plot\n",
    "    ax.set_boundary(rect, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Set title for each subplot\n",
    "    if names:\n",
    "        ax.set_title(f'{abcd[i]}) {names[i]}',fontsize=11,loc='left')\n",
    "    else:\n",
    "        ax.set_title(f'Cluster {i+1}',fontsize=11,loc='left')\n",
    "\n",
    "# # Hide any unused subplots\n",
    "# for j in range(i + 1, n_rows * n_cols):\n",
    "#     fig.delaxes(axes[j // n_cols, j % n_cols])\n",
    "\n",
    "\n",
    "# Replace the last axes (i=5) with a standard 2D axes\n",
    "i = 5\n",
    "row = i // n_cols\n",
    "col = i % n_cols\n",
    "\n",
    "# Remove the map-projection axes\n",
    "fig.delaxes(axes[row, col])\n",
    "\n",
    "# Create a new regular axes in the same position\n",
    "# Get the position of the subplot we're replacing\n",
    "position = fig.add_subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "# Shrink and slightly shift the subplot to better match map subplots\n",
    "box = position.get_position()\n",
    "position.set_position([box.x0, box.y0+0.065, box.width*0.9, box.height*0.8])\n",
    "\n",
    "axes[row, col] = position  # update in the axes array\n",
    "ax = axes[row, col]\n",
    "\n",
    "for k in range(2,11):\n",
    "    ax.scatter(np.repeat(k,k),\n",
    "             dic_results_best_k['reproducibility'][k-2],color='k',s=2)\n",
    "    ax.scatter(k,\n",
    "             np.mean(dic_results_best_k['reproducibility'][k-2]),\n",
    "                    color='orange',s=20)\n",
    "ax.scatter(k,\n",
    "         np.mean(dic_results_best_k['reproducibility'][k-2]),\n",
    "                color='orange',s=20,label='Average clusters')\n",
    "    # axes[1].axhline(0,color='k')\n",
    "ax.set_xlabel('Number of clusters (k)',fontsize=11)\n",
    "ax.set_ylabel('Reproducibility',fontsize=11)\n",
    "ax.set_title('f) Reproducibility Index',loc='left',fontsize=11)\n",
    "ax.set_xticks(np.arange(2,11),fontsize=11)\n",
    "\n",
    "ax.yaxis.tick_right()\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "ax.grid(alpha=0.2,ls='--')\n",
    "# ax.legend()\n",
    "\n",
    "# # Adjust layout to prevent overlapping\n",
    "cax = fig.add_axes([0.92, 0.6, 0.01, 0.25])  # Example position: horizontal, below the main plot\n",
    "# Add a horizontal colorbar\n",
    "ticks_1 = [-1, -0.5, 0, 0.5, 1]\n",
    "cbar = fig.colorbar(mesh, cax=cax, orientation='vertical',ticks=ticks_1)\n",
    "cbar.set_label(r'Z Anomaly ($\\sigma$)')\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "if path_save==False:\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "else:\n",
    "    plt.savefig(path_save, bbox_inches='tight',dpi=100)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d831696-b5b2-4ae0-97e3-1a2fb24cd476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd82c66f-2fc8-43d3-8ba6-4d5bfd75b350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[180, 330, 20, 80]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regioncoords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:weather_regimes]",
   "language": "python",
   "name": "conda-env-weather_regimes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
